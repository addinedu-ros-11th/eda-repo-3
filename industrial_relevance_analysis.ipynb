{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384381a0",
   "metadata": {},
   "source": [
    "\n",
    "# Industrial Relevance Mapping – Analysis Notebook\n",
    "_Last generated: 2025-10-24 07:46_\n",
    "\n",
    "This notebook maps **open-source repos** to **industrial relevance** and **tech-core strength**.\n",
    "\n",
    "## Files\n",
    "- **Input CSV (default)**: `/mnt/data/repos_top10.csv`\n",
    "- **Exports**: scatter plot to `/mnt/data/tech_vs_industry_scatter.png`\n",
    "\n",
    "> You can replace the CSV with your larger dataset any time. Required columns:\n",
    "`full_name, language, stargazers_count, activity_from_cutoff, contributors_from_cutoff, issue_close_rate, pr_merge_rate, score`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7d8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "INPUT_CSV = \"/mnt/data/repos_top10.csv\"  # change to your CSV path\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_scores(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    numeric_cols = [\n",
    "        \"stargazers_count\",\"activity_from_cutoff\",\"contributors_from_cutoff\",\n",
    "        \"issue_close_rate\",\"pr_merge_rate\",\"score\"\n",
    "    ]\n",
    "    for c in numeric_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    norm_cols = [\"stargazers_count\",\"activity_from_cutoff\",\"contributors_from_cutoff\",\"issue_close_rate\",\"pr_merge_rate\"]\n",
    "    df[[f\"norm_{c}\" for c in norm_cols]] = scaler.fit_transform(df[norm_cols])\n",
    "\n",
    "    # ---- Heuristics (edit weights as needed) ----\n",
    "    df[\"industrial_linkage_score\"] = (\n",
    "        0.35*df[\"norm_contributors_from_cutoff\"]\n",
    "        +0.20*df[\"norm_activity_from_cutoff\"]\n",
    "        +0.20*df[\"norm_issue_close_rate\"]\n",
    "        +0.15*df[\"norm_pr_merge_rate\"]\n",
    "        +0.10*df[\"norm_stargazers_count\"]\n",
    "    )\n",
    "\n",
    "    lang_prior = {\"Python\": 1.0, \"C++\": 0.9, \"C#\": 0.85, \"Unknown\": 0.7}\n",
    "    df[\"lang_prior\"] = df[\"language\"].map(lang_prior).fillna(0.75)\n",
    "    df[\"tech_core_score\"] = (\n",
    "        0.45*df[\"norm_stargazers_count\"]\n",
    "        +0.20*df[\"norm_pr_merge_rate\"]\n",
    "        +0.20*df[\"norm_issue_close_rate\"]\n",
    "        +0.15*df[\"lang_prior\"]\n",
    "    )\n",
    "\n",
    "    df[\"industrial_x_tech\"] = 0.5*df[\"industrial_linkage_score\"] + 0.5*df[\"tech_core_score\"]\n",
    "    return df\n",
    "\n",
    "scored = compute_scores(df)\n",
    "scored.sort_values(\"industrial_x_tech\", ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e96d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_scatter(df_scored: pd.DataFrame, x=\"tech_core_score\", y=\"industrial_linkage_score\", label_col=\"full_name\", title=\"Tech vs Industrial Map\"):\n",
    "    plt.figure()\n",
    "    plt.scatter(df_scored[x], df_scored[y])\n",
    "    for _, r in df_scored.iterrows():\n",
    "        plt.annotate(r[label_col], (r[x], r[y]), xytext=(5,5), textcoords=\"offset points\", fontsize=7)\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.title(title)\n",
    "    out_png = \"/mnt/data/tech_vs_industry_scatter.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160)\n",
    "    plt.close()\n",
    "    return out_png\n",
    "\n",
    "out_path = plot_scatter(scored)\n",
    "out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rank_by_ind = scored.sort_values(\"industrial_linkage_score\", ascending=False)\n",
    "rank_by_tech = scored.sort_values(\"tech_core_score\", ascending=False)\n",
    "rank_by_combo = scored.sort_values(\"industrial_x_tech\", ascending=False)\n",
    "\n",
    "rank_by_ind.head(10), rank_by_tech.head(10), rank_by_combo.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b73f8e",
   "metadata": {},
   "source": [
    "\n",
    "## Next Steps\n",
    "- Replace the CSV with your expanded dataset (e.g., 100–500 repos).\n",
    "- (Optional) Add columns like `topics`, `org_type_fork_share`, `corp_contributor_ratio` and extend the scoring.\n",
    "- Export charts/tables for reports.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
