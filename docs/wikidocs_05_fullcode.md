# 5. ì „ì²´ ì‹¤í–‰ ì½”ë“œ

ì´ í˜ì´ì§€ëŠ” **ì „ì²´ ì‹¤í–‰ ê°€ëŠ¥í•œ Python ì½”ë“œ**ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì•„ë˜ ì½”ë“œë¥¼ Jupyter Notebookì— ë³µì‚¬í•˜ê±°ë‚˜ `.py` íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## 5-1. ì‚¬ì „ ì¤€ë¹„ ì‚¬í•­

### í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install requests pandas numpy matplotlib tqdm python-dotenv
```

### GitHub í† í° ì„¤ì •
`.env` íŒŒì¼ ìƒì„± (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬):
```bash
GITHUB_TOKEN=ghp_your_token_here
```

---

## 5-2. ì™„ì „í•œ ì‹¤í–‰ ì½”ë“œ

ì•„ë˜ ì½”ë“œëŠ” **í•˜ë‚˜ì˜ Python ìŠ¤í¬ë¦½íŠ¸**ë¡œ ì „ì²´ ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. Jupyter Notebookì´ë‚˜ Python íŒŒì¼ì— ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•˜ì„¸ìš”.

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë¡œë³´í‹±ìŠ¤ íŠ¸ë Œë”© ì €ì¥ì†Œ ë¶„ì„ - ì™„ì „í•œ ì‹¤í–‰ ì½”ë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì„¤ëª…: ìµœê·¼ 90ì¼ ë™ì•ˆ ê°€ì¥ ë§ì€ ë³„ì ì„ ë°›ì€ ë¡œë³´í‹±ìŠ¤ ì €ì¥ì†Œ Top 100 ì°¾ê¸°
# GraphQL API ì—­ë°©í–¥ í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ REST API í•œê³„ ìš°íšŒ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Required imports
import os, time, datetime as dt
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import FuncFormatter
from tqdm import tqdm
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# GitHub API Configuration
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
if not GITHUB_TOKEN:
    raise ValueError("GitHub token required! Set GITHUB_TOKEN in .env file")

SESSION = requests.Session()
SESSION.headers.update({
    "Accept": "application/vnd.github+json",
    "Authorization": f"Bearer {GITHUB_TOKEN}",
    "X-GitHub-Api-Version": "2022-11-28",
    "User-Agent": "trending-robotics/1.0"
})

# API Endpoints
API_BASE = "https://api.github.com"
SEARCH_API = f"{API_BASE}/search/repositories"
STARS_API = f"{API_BASE}/repos/{{owner}}/{{repo}}/stargazers"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Search Configuration - MODIFY THESE TO CHANGE SEARCH BEHAVIOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TOPIC = "robot"                    # GitHub topic to search
DESCRIPTION_KEYWORD = "robot"       # Keyword in description (set None to disable)
                                    # Examples: "robotics", "ROS2", "autonomous"

DAYS_WINDOW = 90                    # Days of recent stars to analyze
PUSH_WINDOW_DAYS = 365              # Days of pushed activity (1 year to include legacy projects)
MIN_STARS = 100                     # Minimum total stars to consider (filters low-quality repos)
TOP_N = 100                         # Number of top repos to return
VISUALIZE_TOP_N = 30                # Number of repos to visualize

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API & Performance Settings
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESULTS_PER_PAGE = 100              # Max results per API page
SLEEP_TIME = 2                      # Seconds between API calls
PUSH_BUCKET_DAYS = 30               # Days per pushed-date window (increased for 1-year range)
MAX_RETRIES = 3                     # Max retries for failed API calls

print("âœ… Configuration loaded")
print(f"   Topic: {TOPIC}")
print(f"   Description Keyword: {DESCRIPTION_KEYWORD}")
print(f"   Star Analysis Window: Last {DAYS_WINDOW} days")
print(f"   Pushed Activity Window: Last {PUSH_WINDOW_DAYS} days")
print(f"   Minimum Stars: {MIN_STARS}")
print(f"   Target: Top {TOP_N} repositories")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Helper Functions
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def github_api_call(url: str, params: dict = None, headers: dict = None, max_retries: int = 3) -> dict:
    """GitHub API í˜¸ì¶œ with rate limit handling and retries"""
    retries = 0
    while retries < max_retries:
        try:
            resp = SESSION.get(url, params=params, headers=headers, timeout=30)
            
            # Rate limit check
            if resp.status_code == 403 and "X-RateLimit-Remaining" in resp.headers:
                reset_time = int(resp.headers["X-RateLimit-Reset"])
                sleep_time = max(reset_time - time.time() + 1, 1)
                print(f"â³ Rate limit hit. Waiting {sleep_time:.0f}s...")
                time.sleep(sleep_time)
                continue
                
            resp.raise_for_status()
            return resp.json()
            
        except Exception as e:
            retries += 1
            if retries >= max_retries:
                print(f"âŒ Max retries exceeded for {url}: {str(e)}")
                return {}
            print(f"âš ï¸  API error (retry {retries}/{max_retries}): {str(e)}")
            time.sleep(5)
    
    return {}


def get_recent_stars(owner: str, repo: str, since_date: str, max_pages: int = None) -> int:
    """
    GraphQL APIë¡œ ìµœê·¼ ë³„ì ë§Œ ì—­ìˆœ í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ì¡°íšŒ
    REST APIì˜ 400í˜ì´ì§€ í•œê³„ë¥¼ ìš°íšŒí•˜ì—¬ ìµœê·¼ ë°ì´í„°ì— ì§ì ‘ ì ‘ê·¼
    
    Args:
        owner: ì €ì¥ì†Œ ì†Œìœ ì
        repo: ì €ì¥ì†Œ ì´ë¦„
        since_date: ê¸°ì¤€ ë‚ ì§œ (ISO 8601)
        max_pages: ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (None=ì œí•œ ì—†ìŒ, 90ì¼ ì´ì „ê¹Œì§€ ì „ë¶€ ìˆ˜ì§‘)
    
    Returns:
        ìµœê·¼ 90ì¼ ì´ë‚´ ë³„ì  ìˆ˜
    """
    
    # GraphQL ì¿¼ë¦¬: ì—­ìˆœ í˜ì´ì§€ë„¤ì´ì…˜ (ìµœì‹ ë¶€í„°)
    query = """
    query($owner: String!, $repo: String!, $last: Int!, $before: String) {
      repository(owner: $owner, name: $repo) {
        stargazers(last: $last, before: $before) {
          edges {
            starredAt
            cursor
          }
          pageInfo {
            hasPreviousPage
            startCursor
          }
        }
      }
    }
    """
    
    headers = {
        "Authorization": f"token {GITHUB_TOKEN}",
        "Content-Type": "application/json"
    }
    
    graphql_url = "https://api.github.com/graphql"
    
    recent_count = 0
    before_cursor = None
    found_old_star = False
    page = 0
    
    while True:
        page += 1
        
        # max_pages ì œí•œì´ ìˆìœ¼ë©´ ì²´í¬
        if max_pages and page > max_pages:
            break
        
        # ì•ˆì „ì¥ì¹˜: ìµœëŒ€ 200í˜ì´ì§€ (20,000ê°œ)
        if page > 200:
            break
        
        variables = {
            "owner": owner,
            "repo": repo,
            "last": 100,  # GraphQL í•œê³„
            "before": before_cursor
        }
        
        try:
            response = SESSION.post(
                graphql_url,
                json={"query": query, "variables": variables},
                headers=headers,
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                
                if "errors" in data:
                    # GraphQL ì—ëŸ¬ ë°œìƒ ì‹œ ì¡°ìš©íˆ 0 ë°˜í™˜ (ì‹ ê·œ ì €ì¥ì†Œì¼ ìˆ˜ ìˆìŒ)
                    return 0
                
                stargazers = data.get("data", {}).get("repository", {}).get("stargazers", {})
                edges = stargazers.get("edges", [])
                page_info = stargazers.get("pageInfo", {})
                
                if not edges:
                    break
                
                # í˜„ì¬ í˜ì´ì§€ì˜ ìµœê·¼ ë³„ì  ì¹´ìš´íŠ¸
                for edge in edges:
                    starred_at = edge.get("starredAt", "")
                    if starred_at >= since_date:
                        recent_count += 1
                    else:
                        found_old_star = True
                
                # 90ì¼ ì´ì „ ë³„ì ì„ ë§Œë‚˜ë©´ ì¤‘ë‹¨ (ë” ì´ìƒ ìµœê·¼ ë³„ì  ì—†ìŒ)
                if found_old_star:
                    break
                
                # ì´ì „ í˜ì´ì§€ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                if not page_info.get("hasPreviousPage"):
                    break
                
                # ë‹¤ìŒ í˜ì´ì§€ ì»¤ì„œ
                before_cursor = page_info.get("startCursor")
                time.sleep(1)  # Rate limit ë°©ì§€
                
            elif response.status_code == 429:
                # Rate limit ëŒ€ê¸°
                time.sleep(60)
            else:
                break
                
        except Exception as e:
            break
    
    return recent_count


def daterange(start: dt.date, end: dt.date, step_days: int):
    """Generate date ranges for sharding"""
    cur = start
    delta = dt.timedelta(days=step_days-1)
    while cur <= end:
        window_end = min(end, cur + delta)
        yield cur, window_end
        cur = window_end + dt.timedelta(days=1)


def iso_date(d: dt.date) -> str:
    """Convert date to ISO format"""
    return d.isoformat()


print("âœ… Helper functions defined")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Repository Search
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Calculate time windows
since_date = (dt.datetime.utcnow() - dt.timedelta(days=DAYS_WINDOW)).isoformat()
end_date = dt.date.today()
start_date = end_date - dt.timedelta(days=PUSH_WINDOW_DAYS-1)

# Build pushed-date windows
windows = list(daterange(start_date, end_date, PUSH_BUCKET_DAYS))

print(f"ğŸ” Searching repositories...")
print(f"   Pushed window: {start_date} to {end_date} ({len(windows)} shards)")
print(f"   Star counting since: {since_date[:10]}")
print(f"   Minimum stars: {MIN_STARS}\n")

# Build search query with minimum stars filter
if DESCRIPTION_KEYWORD:
    query_template = f'(topic:{TOPIC} OR ({DESCRIPTION_KEYWORD} in:description)) stars:>={MIN_STARS} pushed:{{start}}..{{end}}'
    print(f"   Query: (topic:{TOPIC} OR {DESCRIPTION_KEYWORD} in description) AND stars >= {MIN_STARS}")
else:
    query_template = f'topic:{TOPIC} stars:>={MIN_STARS} pushed:{{start}}..{{end}}'
    print(f"   Query: topic:{TOPIC} AND stars >= {MIN_STARS}")

# Search repositories across all windows
all_repos = {}

for start, end in windows:
    query = query_template.format(start=iso_date(start), end=iso_date(end))
    page = 1
    
    while page <= 10:  # Max 10 pages per window (1,000 results)
        resp = github_api_call(
            SEARCH_API,
            params={
                "q": query,
                "sort": "stars",
                "order": "desc",
                "per_page": RESULTS_PER_PAGE,
                "page": page
            }
        )
        
        if not resp or "items" not in resp:
            break
            
        repos = resp["items"]
        if not repos:
            break
            
        # Add repos (dict for deduplication)
        for repo in repos:
            all_repos[repo["full_name"]] = repo
            
        if page * RESULTS_PER_PAGE >= 1000:
            break
            
        page += 1
        time.sleep(SLEEP_TIME)

print(f"\nâœ… Found {len(all_repos):,} unique repositories (stars >= {MIN_STARS})")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Recent Stars Counting
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print(f"â­ Counting recent stars for {len(all_repos):,} repositories...")
print(f"âš ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: ì•½ 30-60ë¶„ (ë¬´ì œí•œ ìˆ˜ì§‘)")
print("=" * 80)
print()

trending = []

for repo in tqdm(all_repos.values(), desc="Processing repos"):
    owner, name = repo["full_name"].split("/")
    
    # max_pages=Noneìœ¼ë¡œ ë¬´ì œí•œ ìˆ˜ì§‘ (90ì¼ ì´ì „ê¹Œì§€ ì „ë¶€)
    recent_stars = get_recent_stars(owner, name, since_date, max_pages=None)
    
    if recent_stars > 0:
        # Use max() to handle cases where stars were added during collection
        # This prevents recent_stars > total_stars timing issues
        total_stars = max(repo["stargazers_count"], recent_stars)
        
        trending.append({
            "full_name": repo["full_name"],
            "description": repo["description"],
            "language": repo["language"],
            "total_stars": total_stars,
            "recent_stars": recent_stars,
            "url": repo["html_url"],
            "topics": ",".join(repo.get("topics", []))
        })
        
    time.sleep(SLEEP_TIME)

# Sort and get top N
result_df = pd.DataFrame(trending)
result_df = result_df.sort_values("recent_stars", ascending=False).head(TOP_N)

print(f"\nâœ… Completed! Top {TOP_N} repositories identified")
print(f"   Total with recent stars: {len(trending):,}")
print(f"   Average recent stars (top {TOP_N}): {result_df['recent_stars'].mean():.1f}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Save Results
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Save to CSV
timestamp = dt.datetime.now().strftime("%Y%m%d_%H%M")
out_csv = f"robotics_trending_top{TOP_N}_{timestamp}.csv"

result_df.to_csv(out_csv, index=False, encoding="utf-8")
print(f"âœ… Saved to: {out_csv}\n")

# Display top 10
print("=" * 80)
print(f"TOP 10 TRENDING REPOSITORIES (Last {DAYS_WINDOW} days)")
print("=" * 80)

for idx, repo in result_df.head(10).iterrows():
    print(f"\n{idx + 1}. {repo['full_name']}")
    print(f"   Recent stars: {repo['recent_stars']:,} | Total: {repo['total_stars']:,}")
    print(f"   Language: {repo['language'] or 'Not specified'}")
    if repo['description']:
        print(f"   {repo['description'][:100]}...")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Visualization
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Prepare visualization data
top_n_df = result_df.head(VISUALIZE_TOP_N).copy()
top_n_df['repo_name'] = top_n_df['full_name'].apply(lambda x: x.split('/')[-1])

# Setup matplotlib
plt.rcParams['figure.figsize'] = (18, 16)
plt.rcParams['font.size'] = 10

# Create subplots
fig, (ax1, ax2, ax3) = plt.subplots(3, 1, height_ratios=[3, 2.5, 2])

# Color palette
colors = plt.cm.tab20(np.linspace(0, 1, 20))
colors = np.vstack((colors, plt.cm.Set3(np.linspace(0, 1, 10))))

# Plot bars
bars1 = ax1.bar(range(10), top_n_df['recent_stars'].head(10), color=colors[:10])
bars2 = ax2.bar(range(10), top_n_df['recent_stars'].iloc[10:20], color=colors[10:20])
bars3 = ax3.bar(range(10), top_n_df['recent_stars'].iloc[20:30], color=colors[20:30])

# Titles
ax1.set_title('Top 10 Trending Robotics Repositories', fontsize=14, pad=20)
ax2.set_title('11-20th Trending Repositories', fontsize=14, pad=20)
ax3.set_title('21-30th Trending Repositories', fontsize=14, pad=20)

# Helper functions
def add_value_labels(ax, bars):
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, height,
                f'{int(height):,}', ha='center', va='bottom', fontsize=9)

def setup_axes(ax, repos):
    ax.set_xticks(range(len(repos)))
    ax.set_xticklabels(repos, rotation=45, ha='right')
    ax.set_ylabel('Recent Stars', fontsize=12, labelpad=10)
    ax.yaxis.grid(True, linestyle='--', alpha=0.7)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)
    ax.yaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))

# Apply formatting
add_value_labels(ax1, bars1)
add_value_labels(ax2, bars2)
add_value_labels(ax3, bars3)
setup_axes(ax1, top_n_df['repo_name'].head(10).tolist())
setup_axes(ax2, top_n_df['repo_name'].iloc[10:20].tolist())
setup_axes(ax3, top_n_df['repo_name'].iloc[20:30].tolist())

plt.tight_layout()
plt.show()

# Statistics
print("\n" + "=" * 80)
print("STATISTICS")
print("=" * 80)
print(f"Total recent stars (top {VISUALIZE_TOP_N}): {top_n_df['recent_stars'].sum():,}")
print(f"Average: {top_n_df['recent_stars'].mean():.1f}")
print(f"Median: {top_n_df['recent_stars'].median():.1f}")
print(f"Total cumulative stars: {top_n_df['total_stars'].sum():,}")

# Language distribution
lang_stats = top_n_df['language'].value_counts()
print(f"\nLanguage Distribution (top {VISUALIZE_TOP_N}):")
for lang, count in lang_stats.head(5).items():
    percentage = (count / len(top_n_df)) * 100
    lang_name = lang if pd.notna(lang) else 'Not specified'
    print(f"  {lang_name}: {count} repos ({percentage:.1f}%)")

print("\n" + "=" * 80)
print("âœ… ë¶„ì„ ì™„ë£Œ!")
print("=" * 80)
```

---

## 5-3. ì‹¤í–‰ ë°©ë²•

### Jupyter Notebookì—ì„œ ì‹¤í–‰
1. ìƒˆ Notebook ìƒì„±
2. ìœ„ ì½”ë“œë¥¼ í•˜ë‚˜ì˜ ì…€ì— ë³µì‚¬
3. ì…€ ì‹¤í–‰ (Shift + Enter)
4. ì•½ 30-60ë¶„ ëŒ€ê¸°

### Python íŒŒì¼ë¡œ ì‹¤í–‰
1. `robotics_trending.py` íŒŒì¼ ìƒì„±
2. ìœ„ ì½”ë“œ ë³µì‚¬
3. í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰:
```bash
python robotics_trending.py
```

---

## 5-4. ì¶œë ¥ íŒŒì¼

ì‹¤í–‰ ì™„ë£Œ í›„ ë‹¤ìŒ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤:

| íŒŒì¼ëª… | ì„¤ëª… |
|--------|------|
| `robotics_trending_top100_YYYYMMDD_HHMM.csv` | Top 100 ì €ì¥ì†Œ ë°ì´í„° (CSV) |

**CSV íŒŒì¼ ì»¬ëŸ¼:**
- `full_name`: ì €ì¥ì†Œ ì „ì²´ ì´ë¦„ (owner/repo)
- `description`: ì €ì¥ì†Œ ì„¤ëª…
- `language`: ì£¼ìš” í”„ë¡œê·¸ë˜ë° ì–¸ì–´
- `total_stars`: ì´ ë³„ì  ìˆ˜
- `recent_stars`: ìµœê·¼ 90ì¼ ë³„ì  ìˆ˜
- `url`: GitHub URL
- `topics`: ì €ì¥ì†Œ í† í”½ (ì‰¼í‘œ êµ¬ë¶„)

---

## 5-5. ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ë‹¤ë¥¸ í† í”½ìœ¼ë¡œ ë³€ê²½
```python
TOPIC = "ros2"  # ROS2 ì €ì¥ì†Œ ê²€ìƒ‰
DESCRIPTION_KEYWORD = "ros2"
```

### AI ê´€ë ¨ ì €ì¥ì†Œ ê²€ìƒ‰
```python
TOPIC = "artificial-intelligence"
DESCRIPTION_KEYWORD = "AI"
```

### ìµœê·¼ 30ì¼ë§Œ ë¶„ì„
```python
DAYS_WINDOW = 30  # 30ì¼ë¡œ ë³€ê²½
```

### Top 50ìœ¼ë¡œ ì¶•ì†Œ
```python
TOP_N = 50  # 50ê°œë¡œ ë³€ê²½
VISUALIZE_TOP_N = 30
```

---

## 5-6. ì„±ëŠ¥ ìµœì í™”

### ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì œí•œ ëª¨ë“œ)
```python
# get_recent_stars() í˜¸ì¶œ ì‹œ max_pages ì¶”ê°€
recent_stars = get_recent_stars(owner, name, since_date, max_pages=5)
```
- 5í˜ì´ì§€ë§Œ ìˆ˜ì§‘ (ìµœëŒ€ 500ê°œ ë³„ì )
- ì‹¤í–‰ ì‹œê°„: ì•½ 5-10ë¶„
- ì •í™•ë„: ìµœê·¼ ë³„ì ì´ ë§ì€ ì €ì¥ì†ŒëŠ” ê³¼ì†Œ ì¸¡ì •ë  ìˆ˜ ìˆìŒ

### ì „ì²´ ë°ì´í„° ìˆ˜ì§‘ (ì •í™• ëª¨ë“œ)
```python
# í˜„ì¬ ê¸°ë³¸ê°’
recent_stars = get_recent_stars(owner, name, since_date, max_pages=None)
```
- ë¬´ì œí•œ í˜ì´ì§€ ìˆ˜ì§‘ (90ì¼ ì´ì „ê¹Œì§€)
- ì‹¤í–‰ ì‹œê°„: ì•½ 30-60ë¶„
- ì •í™•ë„: 100% (ëª¨ë“  ìµœê·¼ ë³„ì  ìˆ˜ì§‘)

---

## ë‹¤ìŒ ë‹¨ê³„
- **[6. ë¬¸ì œ í•´ê²° ê°€ì´ë“œ](wikidocs_06_troubleshooting.md)**: ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ í•´ê²°

---

**ëª©ì°¨ë¡œ ëŒì•„ê°€ê¸°:** [0. ì‹œì‘í•˜ê¸°](wikidocs_00_index.md)
